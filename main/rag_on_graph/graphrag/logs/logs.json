{
    "type": "error",
    "data": "Error Invoking LLM",
    "stack": "Traceback (most recent call last):\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/openai/_base_client.py\", line 1839, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/openai/_base_client.py\", line 1533, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/openai/_base_client.py\", line 1634, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': 'Output data may contain inappropriate content. (request id: 202411301511409153057790531811)', 'type': 'upstream_error', 'param': '400', 'code': 'bad_response_status_code'}}\n",
    "source": "Error code: 400 - {'error': {'message': 'Output data may contain inappropriate content. (request id: 202411301511409153057790531811)', 'type': 'upstream_error', 'param': '400', 'code': 'bad_response_status_code'}}",
    "details": {
        "input": "MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n"
    }
}
{
    "type": "error",
    "data": "Entity Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 122, in __call__\n    result = await self._process_document(text, prompt_variables)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 161, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/openai/json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/openai/openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/openai/openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/openai/_base_client.py\", line 1839, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/openai/_base_client.py\", line 1533, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/openai/_base_client.py\", line 1634, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': 'Output data may contain inappropriate content. (request id: 202411301511409153057790531811)', 'type': 'upstream_error', 'param': '400', 'code': 'bad_response_status_code'}}\n",
    "source": "Error code: 400 - {'error': {'message': 'Output data may contain inappropriate content. (request id: 202411301511409153057790531811)', 'type': 'upstream_error', 'param': '400', 'code': 'bad_response_status_code'}}",
    "details": {
        "doc_index": 0,
        "text": "获得通过专家鉴定的国家专利（不包括实用新型专利、外观设计专利）。\n\n5.在体育竞赛中取得显著成绩，为国家争得荣誉。非体育专业学生参加省（市）级以上体育比赛获得个人项目前三名，集体项目前二名；高水平运动员参加国际和全国性体育比赛获得个人项目前三名、集体项目前二名。集体项目应为上场主力队员。\n\n6.在艺术展演方面取得显著成绩，参加全国大学生艺术展演获得一、二等奖，参加省（市）级艺术展演获得一等奖；艺术类专业学生参加国际和全国性比赛获得前三名。集体项目应为主要演员。\n\n7.获全国十大杰出青年、中国青年五四奖章、中国大学生年度人物等全国性荣誉称号。\n\n8.其它应当认定为表现非常突出的情形。\n\n第五条  获得国家奖学金的学生为在校生中二年级以上（含二年级）学生。同一学年内，获得国家奖学金的家庭经济困难学生可以同时申请并获得国家助学金，但不能同时获得国家励志奖学金或上海市奖学金。\n\n第三章  奖学金评审\n\n第六条  国家奖学金评审坚持公开、公平、公正、择优的原则，实行等额评审，每学年评审一次。\n\n第七条  国家奖学金获奖名额每年按照全国学生资助管理中心分配的名额确定。\n\n第八条  学校成立本科生奖学金评审领导小组，设立评审委员会。评审领导小组由学校分管领导任组长，相关部门负责人为成员，全面领导评审工作。评审委员会由具有代表性的管理人员、专家学者和学生代表组成，具体负责评审工作，向评审领导小组提出国家奖学金评审意见。\n\n第九条  党委学生工作部（处）具体负责组织评审工作，提出当年国家奖学金获奖学生建议名单，报评审领导小组审定后，在校内进行不少于 5 个工作日的公示。\n\n第十条  公示无异议后，每年 10 月 31 日前，学校将评审结果报送全国学生资助管理中心。\n\n第四章  奖学金发放、管理与监督\n\n第十一条  学校于每年 12 月 31 日前将当年国家奖学金一次性发放给获奖学生，并将获奖情况记入学生学籍档案。\n\n第十二条  同一学年内，获得国家奖学金的学生可以同时获得学校优秀奖学金，奖金实行就高发放。\n\n第五章  附 则\n\n第十三条  本办法由党委学生工作部（处）负责解释。\n\n第十四条  本办法自公布之日起施行。原《华东理工大学关于印发<“国家奖学金”管理办法>的通知》（校学〔2007〕45号）同时废止。如上级有关政策有变动，变动之处以上级政策为准。"
    }
}
