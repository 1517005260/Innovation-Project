{
    "type": "error",
    "data": "Error Invoking LLM",
    "stack": "Traceback (most recent call last):\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/openai/_base_client.py\", line 1839, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/openai/_base_client.py\", line 1533, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/openai/_base_client.py\", line 1634, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': 'Output data may contain inappropriate content. (request id: 2024120313293210501635153877833)', 'type': 'upstream_error', 'param': '400', 'code': 'bad_response_status_code'}}\n",
    "source": "Error code: 400 - {'error': {'message': 'Output data may contain inappropriate content. (request id: 2024120313293210501635153877833)', 'type': 'upstream_error', 'param': '400', 'code': 'bad_response_status_code'}}",
    "details": {
        "input": "MANY entities were missed in the last extraction.  Add them below using the same format:\n"
    }
}
{
    "type": "error",
    "data": "Claim Extraction Error",
    "stack": "Traceback (most recent call last):\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/index/graph/extractors/claims/claim_extractor.py\", line 124, in __call__\n    claims = await self._process_document(prompt_args, text, doc_index)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/index/graph/extractors/claims/claim_extractor.py\", line 179, in _process_document\n    response = await self._llm(\n               ^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/openai/json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/openai/openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/openai/openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/caching_llm.py\", line 96, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py\", line 50, in __call__\n    return await self._invoke(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py\", line 54, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 53, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1661, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/openai/_base_client.py\", line 1839, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/openai/_base_client.py\", line 1533, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/ggg/miniconda3/envs/graphrag/lib/python3.11/site-packages/openai/_base_client.py\", line 1634, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': 'Output data may contain inappropriate content. (request id: 2024120313293210501635153877833)', 'type': 'upstream_error', 'param': '400', 'code': 'bad_response_status_code'}}\n",
    "source": "Error code: 400 - {'error': {'message': 'Output data may contain inappropriate content. (request id: 2024120313293210501635153877833)', 'type': 'upstream_error', 'param': '400', 'code': 'bad_response_status_code'}}",
    "details": {
        "doc_index": 0,
        "text": "�，档案由学校退回其家庭所在地，户口应当按照国家相关规定迁回原户籍地或者家庭户籍所在地。\n\n第五章 处分的期限\n\n第三十条 除开除学籍处分以外，纪律处分设置6到12个月的期限，警告、严重警告处分以6个月为期限，记过、留校察看处分以12个月为期限，期间由学生所在学院负责考察，到期按学校规定程序予以解除。处分期限自处分决定书作出之日起计算。\n\n第三十一条 在处分期限内表现良好，无其他违纪行为发生的，学生可在处分期限届满后，向所在学院递交书面申请，学院综合考量其表现情况，提出解除意见，报学校相关职能部门审核并予以书面解除。\n\n留校察看期限内再次发生违纪行为的，给予开除学籍处分。警告、严重警告、记过处分期限内再次发生违纪行为的，按规定从重处分。\n\n第三十二条 有以下情形的，可以申请提前解除处分：\n\n（一）已列入当年就业计划的毕业班学生，在经过的处分期限内表现良好的；\n\n（二）处分期限内有突出进步或立功表现，且处分期限已执行过半的。\n\n第三十三条 解除处分后，学生获得表彰、奖励及其他权益，不再受原处分的影响。学位授予按照学校相关规定执行。\n\n第三十四条 对学生的处分及解除处分材料，学校将真实完整地归入学校文书档案和本人档案。\n\n第六章 附则\n\n第三十五条 学校对接受高等学历继续教育的学生、港澳台侨学生、留学生、交换生、交流生、联合培养研究生的违纪处分，参照本规定执行。\n\n学籍在本校但在外交流交换或联合培养的学生，在交流交换或联合培养期间发生违纪行为，参照本规定执行，若所在交流交换或联合培养的学校已给予处分的，本校予以认可。\n\n第三十六条 本规定所称的“以上”、“以下”、“以内”，包含本数；所称的“不满”、“超过”不包含本数。\n\n第三十七条 本规定自2017年9月1日起施行，原《华东理工大学学生违纪处分条例（试行）》（校通字〔2005〕240号）、《华东理工大学研究生违纪处分条例》（校研〔2014〕78号）同时废止。学校其他相关规定与本规定不一致的，以本规定为准。\n\n \n"
    }
}
